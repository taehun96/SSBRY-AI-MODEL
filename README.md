# ğŸ¤– SSbry - AI í•™ìŠµ ëª¨ë¸

**YOLOv8 ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¶„ë¦¬ë°°ì¶œ AI ëª¨ë¸**

ì‹¤ì‹œê°„ ì“°ë ˆê¸° íƒì§€ ë° 6ì¢… ë¶„ë¥˜ë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ ê°ì²´ ì¸ì‹ ëª¨ë¸

---

## ğŸ“– ëª¨ë¸ ê°œìš”

### YOLOv8ì„ ì„ íƒí•œ ì´ìœ 

YOLOv8n (Nano) ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì“°ë ˆê¸° ë¶„ë¥˜ì— ìµœì í™”ëœ ì»¤ìŠ¤í…€ ëª¨ë¸ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤.

- **ì‹¤ì‹œê°„ íƒì§€**: ëª¨ë°”ì¼ í™˜ê²½ì—ì„œë„ ë¹ ë¥¸ ì¶”ë¡  ì†ë„
- **ë†’ì€ ì •í™•ë„**: ì‘ì€ ëª¨ë¸ í¬ê¸° ëŒ€ë¹„ ìš°ìˆ˜í•œ ë¶„ë¥˜ ì„±ëŠ¥
- **ë‹¤ì¤‘ ê°ì²´ íƒì§€**: í•œ ì´ë¯¸ì§€ì—ì„œ ì—¬ëŸ¬ ì“°ë ˆê¸° ë™ì‹œ ë¶„ë¥˜ ê°€ëŠ¥
- **ì‰¬ìš´ ë°°í¬**: ONNX ë³€í™˜ì„ í†µí•œ Flutter ì•± ì›í™œí•œ ì—°ë™
- **ê²½ëŸ‰í™”**: YOLOv8nìœ¼ë¡œ ëª¨ë°”ì¼ ìµœì í™”

### ì‹œìŠ¤í…œ íë¦„ë„

```
[ì›ë³¸ ì´ë¯¸ì§€]
    â†“
[OpenCV ì „ì²˜ë¦¬]
    â”œâ”€â†’ ê°ì²´ ì˜ì—­ ìë™ ì¶”ì¶œ (Contour Detection)
    â”œâ”€â†’ ë°°ê²½ ë…¸ì´ì¦ˆ ì œê±° (Morphology)
    â””â”€â†’ ì •ê·œí™” ë° ë¦¬ì‚¬ì´ì§•
        â†“
[ë°ì´í„° ì¦ê°•]
    â”œâ”€â†’ ë°ê¸° ë³€í™” (5ë‹¨ê³„)
    â”œâ”€â†’ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ
    â”œâ”€â†’ íšŒì „ ë° ë°˜ì „
    â””â”€â†’ ìŠ¤ì¼€ì¼ ë³€í™”
        â†“
[YOLO ë¼ë²¨ë§]
    â””â”€â†’ (center_x, center_y, width, height)
        â†“
[YOLOv8n í•™ìŠµ]
    â”œâ”€â†’ 30 Epochs
    â”œâ”€â†’ Batch Size: 4
    â””â”€â†’ Image Size: 416x416
        â†“
[best_waste_model.pt]
    â†“
[ONNX ë³€í™˜]
    â””â”€â†’ Opset 17
        â†“
[ëª¨ë°”ì¼ ë°°í¬]
```

---

## ğŸ—‚ï¸ ë°ì´í„°ì…‹ êµ¬ì„±

### ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ (6ì¢…)

| ì¹´í…Œê³ ë¦¬ | ì˜ë¬¸ëª…  |    ì„¤ëª…    |         ì˜ˆì‹œ          |
| :------: | :-----: | :--------: | :-------------------: |
|    ğŸ¥«    |   can   |    ìº”ë¥˜    |  ì•Œë£¨ë¯¸ëŠ„ ìº”, ì²  ìº”   |
|    ğŸ¾    |  glass  |    ìœ ë¦¬    |   ìœ ë¦¬ë³‘, ìœ ë¦¬ ìš©ê¸°   |
|    ğŸ“„    |  paper  |    ì¢…ì´    |   ì‹ ë¬¸ì§€, ë°•ìŠ¤, ì±…    |
|    â™»ï¸    | plastic |  í”Œë¼ìŠ¤í‹±  | í˜íŠ¸ë³‘, í”Œë¼ìŠ¤í‹± ìš©ê¸° |
|    ğŸ“¦    |  vinyl  |    ë¹„ë‹    |   ë¹„ë‹ë´‰ì§€, í¬ì¥ì¬    |
|    ğŸ—‘ï¸    |  trash  | ì¼ë°˜ì“°ë ˆê¸° |  ì¬í™œìš© ë¶ˆê°€ íê¸°ë¬¼   |

### ë°ì´í„° ì¶œì²˜

- **TrashNet Dataset** (Kaggle)
- í´ë˜ìŠ¤ë‹¹ í‰ê·  200 + ì´ë¯¸ì§€
- ì´ ì•½ 8500ì¥

---

## ğŸ”§ ë°ì´í„° ì¦ê°• ì „ëµ

ì €ì¡°ë„ ë° ë‹¤ì–‘í•œ ì¡°ëª… í™˜ê²½ì—ì„œì˜ ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ ì¦ê°• ê¸°ë²•ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.

### 1. ë°ê¸° ë³€í™” ì¦ê°• (5ë‹¨ê³„)

```python
# ë‹¤ì–‘í•œ ì¡°ëª… í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
brightness_levels = {
    'original': None,           # ì›ë³¸
    'dark': 0.6,               # ì–´ë‘ìš´ í™˜ê²½
    'very_dark': 0.4,          # ë§¤ìš° ì–´ë‘ìš´ í™˜ê²½
    'bright': 1.3,             # ë°ì€ í™˜ê²½
    'low_contrast': 'custom'   # ì €ëŒ€ë¹„
}
```

|  ì¦ê°• íƒ€ì…   | Alpha ê°’ | ì„¤ëª…                |
| :----------: | :------: | :------------------ |
|   Original   |   1.0    | ì›ë³¸ ì´ë¯¸ì§€         |
|     Dark     |   0.6    | ì–´ë‘ìš´ ì‹¤ë‚´ í™˜ê²½    |
|  Very Dark   |   0.4    | ì•¼ê°„/ì €ì¡°ë„ í™˜ê²½    |
|    Bright    |   1.3    | ë°ì€ ì•¼ì™¸ í™˜ê²½      |
| Low Contrast |  Custom  | íë¦° ë‚ ì”¨/ê°„ì ‘ ì¡°ëª… |

### 2. ë…¸ì´ì¦ˆ ì¶”ê°€

```python
# ì €ì¡°ë„ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ
gaussian_noise = np.random.normal(0, 25, image.shape)
noisy_image = np.clip(image + gaussian_noise, 0, 255)
```

### 3. ê¸°í•˜í•™ì  ë³€í™˜

- **íšŒì „**: Â±15ë„ ë²”ìœ„ ë‚´ ëœë¤ íšŒì „
- **ì¢Œìš° ë°˜ì „**: 50% í™•ë¥ ë¡œ ì ìš©
- **ìŠ¤ì¼€ì¼ ë³€í™”**: 0.8~1.2 ë°°ìœ¨ ì¡°ì •
- **ì´ë™**: Â±10% ë²”ìœ„ ë‚´ í‰í–‰ ì´ë™

### ì¦ê°• íš¨ê³¼

- **ì›ë³¸ ë°ì´í„°**: 2,000ì¥
- **ì¦ê°• í›„**: 8,500ì¥ (4ë°° ì¦ê°€)
- **í´ë˜ìŠ¤ ê· í˜•**: ê° ì¹´í…Œê³ ë¦¬ë³„ ë™ì¼í•œ ì¦ê°• ì ìš©

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
SSbry/
â”œâ”€â”€ dataset/                      # í•™ìŠµ ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ train/               # í›ˆë ¨ ì´ë¯¸ì§€ (80%)
â”‚   â”‚   â”‚   â”œâ”€â”€ can_001.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ glass_001.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ val/                 # ê²€ì¦ ì´ë¯¸ì§€ (20%)
â”‚   â”‚       â”œâ”€â”€ can_test_001.jpg
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ train/               # í›ˆë ¨ ë¼ë²¨ (YOLO í˜•ì‹)
â”‚       â”‚   â”œâ”€â”€ can_001.txt
â”‚       â”‚   â””â”€â”€ ...
â”‚       â””â”€â”€ val/                 # ê²€ì¦ ë¼ë²¨
â”‚           â”œâ”€â”€ can_test_001.txt
â”‚           â””â”€â”€ ...
â”‚
â”œâ”€â”€ trashnet/                    # ì›ë³¸ ë°ì´í„° (ì¦ê°• ì „)
â”‚   â”œâ”€â”€ can/
â”‚   â”œâ”€â”€ glass/
â”‚   â”œâ”€â”€ paper/
â”‚   â”œâ”€â”€ plastic/
â”‚   â”œâ”€â”€ trash/
â”‚   â””â”€â”€ vinyl/
â”‚
â”œâ”€â”€ runs/                        # í•™ìŠµ ê²°ê³¼
â”‚   â””â”€â”€ detect/
â”‚       â””â”€â”€ waste_classification/
â”‚           â”œâ”€â”€ weights/
â”‚           â”‚   â”œâ”€â”€ best.pt      # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
â”‚           â”‚   â””â”€â”€ last.pt      # ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸
â”‚           â”œâ”€â”€ confusion_matrix.png
â”‚           â”œâ”€â”€ results.png      # í•™ìŠµ ê³¡ì„ 
â”‚           â””â”€â”€ val_batch0_pred.jpg
â”‚
â”œâ”€â”€ best_waste_model.pt          # ìµœì¢… ë°°í¬ ëª¨ë¸
â”œâ”€â”€ yolov8n_trash.onnx           # ONNX ë³€í™˜ ëª¨ë¸
â”œâ”€â”€ dataset.yaml                 # ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼
â”œâ”€â”€ yolov8n.pt                   # YOLOv8 ì‚¬ì „í•™ìŠµ ëª¨ë¸
â”œâ”€â”€ main.ipynb                   # ì „ì²´ ì‹¤í–‰ ë…¸íŠ¸ë¶
â”œâ”€â”€ train.py                     # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ export_onnx.py               # ONNX ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ requirements.txt             # Python ì˜ì¡´ì„±
```

---

## ğŸ¯ ê¸°ìˆ  ìŠ¤íƒ

### Machine Learning

[![YOLOv8](https://img.shields.io/badge/YOLOv8n-Ultralytics-00FFFF?style=flat)](https://github.com/ultralytics/ultralytics)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?style=flat&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![ONNX](https://img.shields.io/badge/ONNX-Runtime-005CED?style=flat&logo=onnx&logoColor=white)](https://onnxruntime.ai/)

### Data Processing

[![OpenCV](https://img.shields.io/badge/OpenCV-4.x-5C3EE8?style=flat&logo=opencv&logoColor=white)](https://opencv.org/)
[![NumPy](https://img.shields.io/badge/NumPy-1.24+-013243?style=flat&logo=numpy&logoColor=white)](https://numpy.org/)
[![Pillow](https://img.shields.io/badge/Pillow-10.x-green?style=flat)](https://pillow.readthedocs.io/)

### Development

[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-F37626?style=flat&logo=jupyter&logoColor=white)](https://jupyter.org/)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=flat&logo=python&logoColor=white)](https://www.python.org/)

---

## ğŸš€ ê°œë°œ í™˜ê²½ ë° í•™ìŠµ ê³¼ì •

### 1ï¸âƒ£ í™˜ê²½ ì„¤ì •

**í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜**

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

**requirements.txt**

```txt
torch>=2.0.0
ultralytics>=8.0.0
opencv-python>=4.8.0
numpy>=1.24.0
Pillow>=10.0.0
matplotlib>=3.7.0
```

**í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­**

- **ìµœì†Œ**: CPU (Intel i5 ì´ìƒ), RAM 8GB
- **ê¶Œì¥**: GPU (CUDA ì§€ì›), RAM 16GB
- **ì €ì¥ê³µê°„**: 5GB ì´ìƒ

### 2ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬

**ìë™ ê°ì²´ íƒì§€ ë° ë¼ë²¨ë§**

```python
import cv2
import numpy as np

def auto_detect_object(image_path):
    """OpenCV ê¸°ë°˜ ê°ì²´ ì˜ì—­ ìë™ ì¶”ì¶œ"""
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # ì´ì§„í™” ë° ëª¨í´ë¡œì§€ ì—°ì‚°
    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
    kernel = np.ones((5,5), np.uint8)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)

    # Contour íƒì§€
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL,
                                    cv2.CHAIN_APPROX_SIMPLE)

    # ê°€ì¥ í° ê°ì²´ ì„ íƒ
    largest_contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(largest_contour)

    return x, y, w, h
```

**YOLO í˜•ì‹ ë¼ë²¨ ìƒì„±**

```python
def convert_to_yolo_format(x, y, w, h, img_width, img_height, class_id):
    """ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    center_x = (x + w/2) / img_width
    center_y = (y + h/2) / img_height
    width = w / img_width
    height = h / img_height

    return f"{class_id} {center_x} {center_y} {width} {height}\n"
```

**ë°ì´í„° ë¶„í• **

- í›ˆë ¨ ë°ì´í„°: 80% (2,000ì¥ â†’ ì¦ê°• í›„ 10,000ì¥)
- ê²€ì¦ ë°ì´í„°: 20% (500ì¥ â†’ ì¦ê°• í›„ 2,500ì¥)

### 3ï¸âƒ£ ëª¨ë¸ í•™ìŠµ

**í•™ìŠµ íŒŒë¼ë¯¸í„°**

```python
from ultralytics import YOLO

# YOLOv8n ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ
model = YOLO('yolov8n.pt')

# í•™ìŠµ ì‹¤í–‰
results = model.train(
    data='dataset.yaml',        # ë°ì´í„°ì…‹ ì„¤ì •
    epochs=30,                  # í•™ìŠµ íšŸìˆ˜
    imgsz=416,                  # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
    batch=4,                    # ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ íš¨ìœ¨)
    device='cpu',               # 'cuda' for GPU
    patience=10,                # Early stopping
    save=True,                  # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    project='runs/detect',      # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
    name='waste_classification',
    exist_ok=True
)
```

**dataset.yaml ì„¤ì •**

```yaml
# ë°ì´í„°ì…‹ ê²½ë¡œ
path: ./dataset
train: images/train
val: images/val

# í´ë˜ìŠ¤ ì •ì˜
nc: 6 # number of classes
names: ["can", "glass", "paper", "plastic", "trash", "vinyl"]
```

**í•™ìŠµ ì‹œê°„**

- CPU: ì•½ 1~2ì‹œê°„
- GPU (CUDA): ì•½ 15~30ë¶„

### 4ï¸âƒ£ ëª¨ë¸ í‰ê°€ ë° ë³€í™˜

**ì„±ëŠ¥ í‰ê°€**

```python
# ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€
metrics = model.val()

print(f"mAP50: {metrics.box.map50}")
print(f"mAP50-95: {metrics.box.map}")
```

**ONNX ë³€í™˜**

```python
# Flutter ì•± ë°°í¬ë¥¼ ìœ„í•œ ONNX ë³€í™˜
model = YOLO('best_waste_model.pt')
model.export(
    format='onnx',
    opset=17,                # Flutter ONNX Runtime í˜¸í™˜
    simplify=True,
    dynamic=False,
    imgsz=416
)
```

---

## ğŸ’» ì‚¬ìš© ë°©ë²•

### Jupyter Notebook ì‹¤í–‰

**main.ipynb**

```python
# 1ë‹¨ê³„: ì„¤ì¹˜ í™•ì¸
!pip list | grep ultralytics

# 2ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„ (ì¦ê°• í¬í•¨)
from data_augmentation import augment_dataset
augment_dataset('trashnet/', 'dataset/')

# 3ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨
from ultralytics import YOLO
model = YOLO('yolov8n.pt')
model.train(data='dataset.yaml', epochs=30)

# 4ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë° í‰ê°€
model = YOLO('runs/detect/waste_classification/weights/best.pt')
results = model.predict('test_image.jpg', save=True)

# 5ë‹¨ê³„: ONNX ë³€í™˜
model.export(format='onnx', opset=17)
```

### ëª…ë ¹ì¤„ ì‹¤í–‰

```bash
# í•™ìŠµ
python train.py --data dataset.yaml --epochs 30 --imgsz 416

# ì¶”ë¡ 
python predict.py --weights best_waste_model.pt --source test_image.jpg

# ONNX ë³€í™˜
python export_onnx.py --weights best_waste_model.pt --opset 17
```

### ê²°ê³¼ í™•ì¸

í•™ìŠµ ì™„ë£Œ í›„ `runs/detect/waste_classification/`ì—ì„œ ë‹¤ìŒ ê²°ê³¼ í™•ì¸:

- **weights/best.pt**: ìµœê³  ì„±ëŠ¥ ëª¨ë¸
- **confusion_matrix.png**: í˜¼ë™ í–‰ë ¬
- **results.png**: í•™ìŠµ ê³¡ì„  (Loss, mAP)
- **val_batch0_pred.jpg**: ê²€ì¦ ê²°ê³¼ ì‹œê°í™”

---

## ğŸ“ˆ ì£¼ìš” íŠ¹ì§•

### ğŸ¯ ìŠ¤ë§ˆíŠ¸ ê°ì²´ íƒì§€

- **OpenCV ê¸°ë°˜ ìë™ ê°ì²´ ì˜ì—­ ì¶”ì¶œ**: Contour Detectionìœ¼ë¡œ ë°°ê²½ê³¼ ê°ì²´ ë¶„ë¦¬
- **ë°°ê²½ ë…¸ì´ì¦ˆ ì œê±°**: ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
- **ìë™ ë¼ë²¨ë§**: ìˆ˜ë™ ì‘ì—… ìµœì†Œí™”

### ğŸŒ“ ë‹¤ì–‘í•œ í™˜ê²½ ëŒ€ì‘

- **5ë‹¨ê³„ ë°ê¸° ë³€í™” ì‹œë®¬ë ˆì´ì…˜**: ì‹¤ë‚´ì™¸ ëª¨ë“  ì¡°ëª… ì¡°ê±´ ì»¤ë²„
- **ì €ì¡°ë„ í™˜ê²½ ë…¸ì´ì¦ˆ ì¶”ê°€**: ì•¼ê°„/ì–´ë‘ìš´ í™˜ê²½ ëŒ€ì‘
- **ì‹¤ì œ ì‚¬ìš© í™˜ê²½ ê³ ë ¤**: ì‚¬ìš©ìê°€ ì´¬ì˜í•˜ëŠ” ë‹¤ì–‘í•œ ê°ë„ì™€ ê±°ë¦¬ ë°˜ì˜

### ğŸ“± ëª¨ë°”ì¼ ìµœì í™”

- **YOLOv8n (Nano) ëª¨ë¸**: íŒŒë¼ë¯¸í„° ìˆ˜ ìµœì†Œí™” (3.2M)
- **ëª¨ë¸ í¬ê¸°**: 6.4MB (ONNX í˜•ì‹)
- **ì¶”ë¡  ì†ë„**: ëª¨ë°”ì¼ CPUì—ì„œ í‰ê·  200ms
- **ONNX Runtime í˜¸í™˜**: Opset 17ë¡œ Flutter ì™„ë²½ ì—°ë™

### ğŸ” ëª¨ë¸ ì„±ëŠ¥

|     ë©”íŠ¸ë¦­      |    ê°’     |
| :-------------: | :-------: |
|      mAP50      | [ê°’ ì…ë ¥] |
|    mAP50-95     | [ê°’ ì…ë ¥] |
|    Precision    | [ê°’ ì…ë ¥] |
|     Recall      | [ê°’ ì…ë ¥] |
| ì¶”ë¡  ì†ë„ (CPU) |  ~200ms   |
|    ëª¨ë¸ í¬ê¸°    |   6.4MB   |

---

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. ONNX Opset ë²„ì „ ë¶ˆì¼ì¹˜

**ë¬¸ì œ**: Flutter ONNX Runtimeì´ Opset 18ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ

```python
# âœ— ê¸°ë³¸ ì„¤ì • (Opset 18)
model.export(format='onnx')

# âœ“ í•´ê²° ë°©ë²•
model.export(format='onnx', opset=17)
```

### 2. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜

**ë¬¸ì œ**: ë°°ì¹˜ í¬ê¸°ê°€ ë„ˆë¬´ ì»¤ì„œ í•™ìŠµ ì¤‘ ë©”ëª¨ë¦¬ ë¶€ì¡±

```python
# âœ— í° ë°°ì¹˜ í¬ê¸°
model.train(data='dataset.yaml', batch=16)

# âœ“ í•´ê²° ë°©ë²•
model.train(data='dataset.yaml', batch=4)
```

### 3. í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ

**ë¬¸ì œ**: íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ì¸ì‹ë¥ ì´ ë‚®ìŒ

**í•´ê²° ë°©ë²•**:

- ë¶€ì¡±í•œ í´ë˜ìŠ¤ì— ëŒ€í•œ ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘
- ì¦ê°• ë¹„ìœ¨ ì¡°ì •ìœ¼ë¡œ í´ë˜ìŠ¤ ê· í˜• ë§ì¶”ê¸°
- Class Weights ì ìš©

```python
# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©
model.train(
    data='dataset.yaml',
    cls_weight=1.5  # ë¶„ë¥˜ ì†ì‹¤ ê°€ì¤‘ì¹˜ ì¦ê°€
)
```

---

## ğŸš€ í–¥í›„ ê°œì„  ê³„íš

### ë‹¨ê¸° ê³„íš

- [ ] ì¶”ê°€ ì“°ë ˆê¸° ì¹´í…Œê³ ë¦¬ í™•ì¥ (ìŒì‹ë¬¼, ì˜ë¥˜ ë“±)
- [ ] ëª¨ë¸ ì–‘ìí™”ë¥¼ í†µí•œ ì¶”ê°€ ê²½ëŸ‰í™” (INT8)
- [ ] ì¬í™œìš© ê°€ëŠ¥/ë¶ˆê°€ëŠ¥ ì„¸ë¶€ ë¶„ë¥˜

### ì¤‘ê¸° ê³„íš

- [ ] ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì´¬ì˜ ëª¨ë“œ ì§€ì›
- [ ] ë‹¤êµ­ì–´ ë¼ë²¨ë§ ë°ì´í„°ì…‹ êµ¬ì¶•
- [ ] ì§€ì—­ë³„ ë¶„ë¦¬ë°°ì¶œ ê·œì • ë°˜ì˜

### ì¥ê¸° ê³„íš

- [ ] Transformer ê¸°ë°˜ ëª¨ë¸ ì‹¤í—˜ (DETR)
- [ ] Edge TPU ìµœì í™”
- [ ] í´ë¼ìš°ë“œ ê¸°ë°˜ ì§€ì† í•™ìŠµ ì‹œìŠ¤í…œ

---

## ğŸ“Š ë°ì´í„°ì…‹ ì¶œì²˜

- **TrashNet Dataset** (Kaggle): ê¸°ë³¸ ì´ë¯¸ì§€ ë°ì´í„°
- **ìì²´ ìˆ˜ì§‘ ë°ì´í„°**: í•œêµ­ í™˜ê²½ì— ë§ëŠ” ì¶”ê°€ ë°ì´í„° 200ì¥
- **ë°ì´í„° ë¼ì´ì„¼ìŠ¤**: CC BY-NC 4.0

---

## ğŸ“ ì°¸ê³ ì‚¬í•­

### í•™ìŠµ ê¶Œì¥ ì‚¬í•­

- **í•™ìŠµ ì‹œê°„**: ì•½ 30ë¶„~1ì‹œê°„ (CPU ê¸°ì¤€)
- **ìµœì†Œ ë°ì´í„°**: í´ë˜ìŠ¤ë‹¹ 200ì¥ ì´ìƒ
- **Epoch**: 30ë²ˆ ì´ìƒ ê¶Œì¥ (Early Stopping ì ìš©)
- **ê¶Œì¥ ì‚¬ì–‘**: RAM 8GB ì´ìƒ, GPU ê¶Œì¥

### ë°ì´í„° ì¦ê°• íŒ

- ë°ê¸° ì¦ê°•ì€ ì‹¤ì œ ì‚¬ìš© í™˜ê²½ ë°˜ì˜ í•„ìˆ˜
- ê³¼ë„í•œ ì¦ê°•ì€ ì˜¤íˆë ¤ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥
- ì›ë³¸ ë°ì´í„° í’ˆì§ˆì´ ê°€ì¥ ì¤‘ìš”

### ëª¨ë¸ ë°°í¬ ì‹œ ì£¼ì˜ì‚¬í•­

- ONNX Opset ë²„ì „ ë°˜ë“œì‹œ í™•ì¸
- ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° ì¼ê´€ì„± ìœ ì§€ (416x416)
- ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë™ì¼í•˜ê²Œ ì ìš©

---

<div align="center">

**AIë¡œ ë§Œë“œëŠ” ì§€ì† ê°€ëŠ¥í•œ ë¯¸ë˜** ğŸŒâ™»ï¸

</div>
