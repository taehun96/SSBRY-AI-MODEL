{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0ba2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2 as cv\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63fc709",
   "metadata": {},
   "source": [
    "### 1ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ì¹˜ í™•ì¸ ë° ì²« ë²ˆì§¸ YOLO í…ŒìŠ¤íŠ¸\n",
    "\n",
    "def check_installation():\n",
    "    \"\"\"ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ë“¤ í™•ì¸\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ” ì„¤ì¹˜ í™•ì¸ ì¤‘...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. PyTorch í™•ì¸\n",
    "    print(f\"âœ… PyTorch: {torch.__version__}\")\n",
    "    print(f\"ğŸ’» Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    \n",
    "    # 2. OpenCV í™•ì¸\n",
    "    print(f\"âœ… OpenCV: {cv.__version__}\")\n",
    "    \n",
    "    # 3. ì¹´ë©”ë¼ í™•ì¸\n",
    "    cap = cv.VideoCapture(0)\n",
    "    if cap.isOpened():\n",
    "        print(\"âœ… ì¹´ë©”ë¼: ì‚¬ìš© ê°€ëŠ¥\")\n",
    "        cap.release()\n",
    "    else:\n",
    "        print(\"âš ï¸ ì¹´ë©”ë¼: ì ‘ê·¼ ë¶ˆê°€ (ë‚˜ì¤‘ì— ë‹¤ì‹œ í™•ì¸)\")\n",
    "    \n",
    "    print(\"\\nğŸ¯ YOLO ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
    "    \n",
    "    # 4. YOLO ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
    "    try:\n",
    "        model = YOLO('yolov8n.pt')  # ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë¨\n",
    "        print(\"âœ… YOLO ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "        \n",
    "        # 5. ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸\n",
    "        dummy_image = np.zeros((640, 640, 3), dtype=np.uint8)\n",
    "        results = model(dummy_image)\n",
    "        print(\"âœ… ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ!\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ YOLO ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def first_yolo_demo():\n",
    "    \"\"\"ì²« ë²ˆì§¸ YOLO ë°ëª¨ - ì›¹ìº ìœ¼ë¡œ ì¼ë°˜ ê°ì²´ íƒì§€\"\"\"\n",
    "    print(\"\\nğŸš€ ì²« ë²ˆì§¸ YOLO ë°ëª¨ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!\")\n",
    "    print(\"(ì¼ë°˜ ê°ì²´ íƒì§€ - ì•„ì§ ì“°ë ˆê¸° ì „ìš© ëª¨ë¸ì€ ì•„ë‹™ë‹ˆë‹¤)\")\n",
    "    print(\"'q' í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.\")\n",
    "    \n",
    "    # YOLO ëª¨ë¸ ë¡œë“œ\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    # ì›¹ìº  ì‹œì‘\n",
    "    cap = cv.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ë‹¤ìŒ ë‹¨ê³„ì—ì„œëŠ” ì´ë¯¸ì§€ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ê² ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # YOLO ì¶”ë¡ \n",
    "        results = model(frame, conf=0.5)\n",
    "        \n",
    "        # ê²°ê³¼ ê·¸ë¦¬ê¸°\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        # í™”ë©´ì— í‘œì‹œ\n",
    "        cv.imshow('YOLO Demo - Press Q to quit', annotated_frame)\n",
    "        \n",
    "        # 'q' í‚¤ë¡œ ì¢…ë£Œ\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print(\"âœ… ë°ëª¨ ì™„ë£Œ!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ì„¤ì¹˜ í™•ì¸\n",
    "    if check_installation():\n",
    "        print(\"\\nğŸ‰ ëª¨ë“  ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        \n",
    "        # ì²« ë°ëª¨ ì‹¤í–‰ ì—¬ë¶€ ë¬»ê¸°\n",
    "        print(\"\\nì²« ë²ˆì§¸ YOLO ë°ëª¨ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\")\n",
    "        print(\"(ì›¹ìº ìœ¼ë¡œ ì¼ë°˜ ê°ì²´ íƒì§€ - ì‚¬ëŒ, ìë™ì°¨, ì»µ ë“±)\")\n",
    "        \n",
    "        # ìë™ìœ¼ë¡œ ì‹¤í–‰ (ì‹¤ì œë¡œëŠ” ì‚¬ìš©ìê°€ ì„ íƒ)\n",
    "        run_demo = input(\"ì‹¤í–‰í•˜ë ¤ë©´ Enter, ê±´ë„ˆë›°ë ¤ë©´ 'n' ì…ë ¥: \").lower()\n",
    "        \n",
    "        if run_demo != 'n':\n",
    "            first_yolo_demo()\n",
    "        \n",
    "        print(\"\\nâœ¨ 1ë‹¨ê³„ ì™„ë£Œ! 2ë‹¨ê³„(ë°ì´í„° ì¤€ë¹„)ë¡œ ë„˜ì–´ê°ˆ ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"\\nâŒ ì„¤ì¹˜ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f13ccca",
   "metadata": {},
   "source": [
    "### 2ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2_augmented_labeling.py\n",
    "def detect_object_in_image(image):\n",
    "    \"\"\"ì´ë¯¸ì§€ì—ì„œ ê°ì²´ì˜ ì‹¤ì œ ìœ„ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ì°¾ê¸°\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    blurred = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, binary = cv.threshold(blurred, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    \n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    cleaned = cv.morphologyEx(binary, cv.MORPH_CLOSE, kernel)\n",
    "    cleaned = cv.morphologyEx(cleaned, cv.MORPH_OPEN, kernel)\n",
    "    \n",
    "    contours, _ = cv.findContours(cleaned, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv.contourArea)\n",
    "        x, y, w, h = cv.boundingRect(largest_contour)\n",
    "        \n",
    "        if w * h < width * height * 0.01:\n",
    "            margin = 0.1\n",
    "            x, y = int(width * margin), int(height * margin)\n",
    "            w, h = int(width * 0.8), int(height * 0.8)\n",
    "        \n",
    "        center_x = (x + w / 2) / width\n",
    "        center_y = (y + h / 2) / height\n",
    "        norm_w = w / width\n",
    "        norm_h = h / height\n",
    "        \n",
    "        return center_x, center_y, norm_w, norm_h\n",
    "    else:\n",
    "        return 0.5, 0.5, 0.8, 0.8\n",
    "\n",
    "def augment_brightness(image):\n",
    "    \"\"\"ë°ê¸° ë³€í™” - ì–´ë‘ìš´/ë°ì€ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "    variations = []\n",
    "    \n",
    "    # 1. ì›ë³¸\n",
    "    variations.append((\"original\", image))\n",
    "    \n",
    "    # 2. ì–´ë‘¡ê²Œ (ì‹¤ë‚´, ê·¸ëŠ˜)\n",
    "    dark = cv.convertScaleAbs(image, alpha=0.6, beta=0)\n",
    "    variations.append((\"dark\", dark))\n",
    "    \n",
    "    # 3. ë§¤ìš° ì–´ë‘¡ê²Œ (ì•¼ê°„, ì €ì¡°ë„)\n",
    "    very_dark = cv.convertScaleAbs(image, alpha=0.4, beta=0)\n",
    "    variations.append((\"very_dark\", very_dark))\n",
    "    \n",
    "    # 4. ë°ê²Œ (í–‡ë¹›)\n",
    "    bright = cv.convertScaleAbs(image, alpha=1.3, beta=10)\n",
    "    variations.append((\"bright\", bright))\n",
    "    \n",
    "    # 5. ëŒ€ë¹„ ì¡°ì • (íë¦° ë‚ )\n",
    "    low_contrast = cv.convertScaleAbs(image, alpha=0.8, beta=0)\n",
    "    variations.append((\"low_contrast\", low_contrast))\n",
    "    \n",
    "    return variations\n",
    "\n",
    "def add_noise(image, noise_level=10):\n",
    "    \"\"\"ë…¸ì´ì¦ˆ ì¶”ê°€ - ì €ì¡°ë„ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "    noise = np.random.normal(0, noise_level, image.shape).astype(np.int16)\n",
    "    noisy = np.clip(image.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    return noisy\n",
    "\n",
    "def setup_augmented_dataset(source_path=\"trashnet\", augment=True):\n",
    "    \"\"\"ë°ì´í„° ì¦ê°•ì„ í¬í•¨í•œ ë°ì´í„°ì…‹ ìƒì„±\"\"\"\n",
    "    source = Path(source_path)\n",
    "    target = Path(\"dataset\")\n",
    "    \n",
    "    if target.exists():\n",
    "        response = input(\"ê¸°ì¡´ dataset í´ë”ë¥¼ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ë§Œë“¤ê¹Œìš”? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            shutil.rmtree(target)\n",
    "        else:\n",
    "            print(\"ì·¨ì†Œë¨\")\n",
    "            return False\n",
    "    \n",
    "    # í´ë” ìƒì„±\n",
    "    for split in ['train', 'val']:\n",
    "        (target / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
    "        (target / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    classes = {'can' : 0,'glass': 1, 'paper': 2, 'plastic': 3, 'trash': 4, 'vinyl' : 5}\n",
    "    \n",
    "    # ëª¨ë“  ì´ë¯¸ì§€ ìˆ˜ì§‘\n",
    "    all_files = []\n",
    "    print(\"\\nì´ë¯¸ì§€ ìˆ˜ì§‘ ì¤‘...\")\n",
    "    for class_name, class_id in classes.items():\n",
    "        class_dir = source / class_name\n",
    "        if class_dir.exists():\n",
    "            count = 0\n",
    "            for ext in ['.jpg', '.jpeg', '.png']:\n",
    "                images = list(class_dir.glob(f\"*{ext}\"))\n",
    "                count += len(images)\n",
    "                for img_path in images:\n",
    "                    all_files.append((img_path, class_id, class_name))\n",
    "            print(f\"  {class_name}: {count}ì¥\")\n",
    "    \n",
    "    if len(all_files) < 10:\n",
    "        print(\"ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ (ìµœì†Œ 10ì¥ í•„ìš”)\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\nì´ {len(all_files)}ì¥ì˜ ì›ë³¸ ì´ë¯¸ì§€\")\n",
    "    \n",
    "    # ëœë¤ ì„ê¸° ë° ë¶„í• \n",
    "    random.shuffle(all_files)\n",
    "    split_idx = int(len(all_files) * 0.8)\n",
    "    \n",
    "    processed = 0\n",
    "    \n",
    "    print(\"\\në°ì´í„° ì²˜ë¦¬ ì¤‘...\")\n",
    "    if augment:\n",
    "        print(\"  ì¦ê°• ì˜µì…˜: ON (ì›ë³¸ + ì–´ë‘ìš´/ë°ì€ ë²„ì „ ìƒì„±)\")\n",
    "        print(\"  ì˜ˆìƒ ì´ ì´ë¯¸ì§€: ì•½ {}ì¥\".format(len(all_files) * 3))\n",
    "    else:\n",
    "        print(\"  ì¦ê°• ì˜µì…˜: OFF (ì›ë³¸ë§Œ)\")\n",
    "    \n",
    "    for i, (img_path, class_id, class_name) in enumerate(all_files):\n",
    "        try:\n",
    "            img = cv.imread(str(img_path))\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv.resize(img, (640, 640))\n",
    "            split = 'train' if i < split_idx else 'val'\n",
    "            \n",
    "            # ì¦ê°• ì ìš©\n",
    "            if augment and split == 'train':  # í›ˆë ¨ ë°ì´í„°ë§Œ ì¦ê°•\n",
    "                variations = augment_brightness(img)\n",
    "                \n",
    "                # ì¼ë¶€ë§Œ ì‚¬ìš© (ì›ë³¸ + 2ê°œ ëœë¤)\n",
    "                selected = [variations[0]]  # ì›ë³¸ì€ í•­ìƒ í¬í•¨\n",
    "                if len(variations) > 1:\n",
    "                    selected.extend(random.sample(variations[1:], min(2, len(variations)-1)))\n",
    "                \n",
    "            else:  # ê²€ì¦ ë°ì´í„°ëŠ” ì›ë³¸ë§Œ\n",
    "                selected = [(\"original\", img)]\n",
    "            \n",
    "            # ê° ë²„ì „ ì €ì¥\n",
    "            for aug_type, aug_img in selected:\n",
    "                # ë…¸ì´ì¦ˆ ì¶”ê°€ (ì–´ë‘ìš´ ë²„ì „ì—ë§Œ)\n",
    "                if \"dark\" in aug_type and random.random() > 0.5:\n",
    "                    aug_img = add_noise(aug_img, noise_level=15)\n",
    "                \n",
    "                # ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±\n",
    "                cx, cy, w, h = detect_object_in_image(aug_img)\n",
    "                \n",
    "                # íŒŒì¼ëª…\n",
    "                img_name = f\"{processed:05d}.jpg\"\n",
    "                \n",
    "                # ì €ì¥\n",
    "                cv.imwrite(str(target / \"images\" / split / img_name), aug_img)\n",
    "                \n",
    "                with open(target / \"labels\" / split / f\"{processed:05d}.txt\", 'w') as f:\n",
    "                    f.write(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "                \n",
    "                processed += 1\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"  ì§„í–‰: {i+1}/{len(all_files)} ì›ë³¸ ì²˜ë¦¬ ({processed}ê°œ ìƒì„±)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ì˜¤ë¥˜ (ê±´ë„ˆëœ€): {img_path.name}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nì²˜ë¦¬ ì™„ë£Œ: {processed}ê°œ ì´ë¯¸ì§€ ìƒì„±\")\n",
    "    \n",
    "    # ìµœì¢… í†µê³„\n",
    "    train_count = len(list((target / \"images\" / \"train\").glob(\"*.jpg\")))\n",
    "    val_count = len(list((target / \"images\" / \"val\").glob(\"*.jpg\")))\n",
    "    print(f\"  í›ˆë ¨: {train_count}ì¥\")\n",
    "    print(f\"  ê²€ì¦: {val_count}ì¥\")\n",
    "    \n",
    "    # dataset.yaml ìƒì„±\n",
    "    yaml_content = \"\"\"path: ./dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "nc: 6\n",
    "names: ['can', 'glass', 'paper', 'plastic', 'trash', 'vinyl']\n",
    "\"\"\"\n",
    "    \n",
    "    with open(\"dataset.yaml\", \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(\"\\ndataset.yaml ìƒì„± ì™„ë£Œ\")\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ë°ì´í„° ì¦ê°• í¬í•¨ ë°ì´í„°ì…‹ ìƒì„±\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    source = input(\"trashnet í´ë” ê²½ë¡œ (ì—”í„°=trashnet): \").strip() or \"trashnet\"\n",
    "    \n",
    "    use_augment = input(\"ë°ì´í„° ì¦ê°• ì‚¬ìš©? (y/n, ì—”í„°=y): \").strip().lower() or 'y'\n",
    "    augment = use_augment == 'y'\n",
    "    \n",
    "    if setup_augmented_dataset(source, augment):\n",
    "        print(\"\\n2ë‹¨ê³„ ì™„ë£Œ!\")\n",
    "        print(\"ë‹¤ìŒ: python step3_train.py ì‹¤í–‰\")\n",
    "    else:\n",
    "        print(\"\\nì‹¤íŒ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5743f2be",
   "metadata": {},
   "source": [
    "### 3ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed237b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ë‹¨ê³„: YOLO ì“°ë ˆê¸° ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨\n",
    "class WasteModelTrainer:\n",
    "    \"\"\"ì“°ë ˆê¸° ë¶„ë¥˜ YOLO ëª¨ë¸ í›ˆë ¨ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_yaml=\"dataset.yaml\"):\n",
    "        self.dataset_yaml = dataset_yaml\n",
    "        self.device = 'cpu'  # CPU ëª¨ë“œ ê³ ì •\n",
    "        \n",
    "        # í›ˆë ¨ ê²°ê³¼ ì €ì¥ ê²½ë¡œ\n",
    "        self.results_path = Path(\"training_results\")\n",
    "        self.results_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        print(f\"ğŸ‹ï¸ YOLO ëª¨ë¸ í›ˆë ¨ ì¤€ë¹„\")\n",
    "        print(f\"ğŸ’» Device: {self.device}\")\n",
    "    \n",
    "    def check_dataset(self):\n",
    "        \"\"\"ë°ì´í„°ì…‹ ìƒíƒœ í™•ì¸\"\"\"\n",
    "        print(\"\\nğŸ” ë°ì´í„°ì…‹ ìƒíƒœ í™•ì¸ ì¤‘...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # YAML íŒŒì¼ í™•ì¸\n",
    "        if not Path(self.dataset_yaml).exists():\n",
    "            print(f\"âŒ {self.dataset_yaml} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "            print(\"2ë‹¨ê³„ì—ì„œ dataset.yamlì„ ìƒì„±í•´ì£¼ì„¸ìš”.\")\n",
    "            return False\n",
    "        \n",
    "        # YAML íŒŒì¼ ì½ê¸°\n",
    "        with open(self.dataset_yaml, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        \n",
    "        dataset_path = Path(config['path'])\n",
    "        train_images = dataset_path / config['train']\n",
    "        val_images = dataset_path / config['val']\n",
    "        train_labels = dataset_path / \"labels\" / \"train\"\n",
    "        val_labels = dataset_path / \"labels\" / \"val\"\n",
    "        \n",
    "        # í´ë” ì¡´ì¬ í™•ì¸\n",
    "        folders_ok = True\n",
    "        for folder, name in [(train_images, \"í›ˆë ¨ ì´ë¯¸ì§€\"), (val_images, \"ê²€ì¦ ì´ë¯¸ì§€\"), \n",
    "                            (train_labels, \"í›ˆë ¨ ë¼ë²¨\"), (val_labels, \"ê²€ì¦ ë¼ë²¨\")]:\n",
    "            if folder.exists():\n",
    "                count = len(list(folder.glob(\"*\")))\n",
    "                print(f\"âœ… {name}: {count}ê°œ\")\n",
    "            else:\n",
    "                print(f\"âŒ {name}: í´ë” ì—†ìŒ\")\n",
    "                folders_ok = False\n",
    "        \n",
    "        # í´ë˜ìŠ¤ ì •ë³´\n",
    "        print(f\"ğŸ“Š í´ë˜ìŠ¤ ìˆ˜: {config['nc']}\")\n",
    "        print(f\"ğŸ·ï¸ í´ë˜ìŠ¤: {config['names']}\")\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if not folders_ok:\n",
    "            print(\"âŒ í•„ìš”í•œ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. 2ë‹¨ê³„ë¥¼ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
    "            return False\n",
    "        \n",
    "        print(\"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "        return True\n",
    "    \n",
    "    def train_model(self, model_size='n', epochs=50, batch_size=8, img_size=640):\n",
    "        \"\"\"ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰\"\"\"\n",
    "        print(f\"\\nğŸš€ ëª¨ë¸ í›ˆë ¨ ì‹œì‘!\")\n",
    "        print(f\"ğŸ“¦ ëª¨ë¸ í¬ê¸°: YOLOv8{model_size}\")\n",
    "        print(f\"ğŸ”„ ì—í¬í¬: {epochs}\")\n",
    "        print(f\"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
    "        print(f\"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {img_size}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # ëª¨ë¸ ë¡œë“œ\n",
    "        model = YOLO(f'yolov8{model_size}.pt')\n",
    "        print(f\"âœ… YOLOv8{model_size} ì‚¬ì „í›ˆë ¨ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "        \n",
    "        # í›ˆë ¨ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # í›ˆë ¨ ì‹¤í–‰\n",
    "            results = model.train(\n",
    "                data=self.dataset_yaml,     # ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼\n",
    "                epochs=epochs,              # í›ˆë ¨ ì—í¬í¬\n",
    "                imgsz=img_size,            # ì´ë¯¸ì§€ í¬ê¸°\n",
    "                batch=batch_size,          # ë°°ì¹˜ í¬ê¸°\n",
    "                device=self.device,        # CPU ì‚¬ìš©\n",
    "                project='runs/detect',     # ê²°ê³¼ ì €ì¥ ê²½ë¡œ\n",
    "                name='waste_classification', # ì‹¤í—˜ ì´ë¦„\n",
    "                save=True,                 # ëª¨ë¸ ì €ì¥\n",
    "                plots=True,                # í›ˆë ¨ ê·¸ë˜í”„ ìƒì„±\n",
    "                patience=10,               # ì¡°ê¸° ì¢…ë£Œ ì¸ë‚´ì‹¬\n",
    "                save_period=10,            # ëª¨ë¸ ì €ì¥ ì£¼ê¸°\n",
    "                workers=2,                 # ë°ì´í„° ë¡œë” ì›Œì»¤ (CPUì—ì„œëŠ” ë‚®ê²Œ)\n",
    "                verbose=True,              # ìƒì„¸ ë¡œê·¸\n",
    "                val=True,                  # ê²€ì¦ ì‹¤í–‰\n",
    "                cache=False,               # ë©”ëª¨ë¦¬ ìºì‹œ (CPUì—ì„œëŠ” False)\n",
    "                amp=False,                 # ìë™ í˜¼í•© ì •ë°€ë„ (CPUì—ì„œëŠ” False)\n",
    "            )\n",
    "            \n",
    "            # í›ˆë ¨ ì‹œê°„ ê³„ì‚°\n",
    "            training_time = time.time() - start_time\n",
    "            hours = int(training_time // 3600)\n",
    "            minutes = int((training_time % 3600) // 60)\n",
    "            seconds = int(training_time % 60)\n",
    "            \n",
    "            print(\"\\nğŸ‰ í›ˆë ¨ ì™„ë£Œ!\")\n",
    "            print(f\"â° í›ˆë ¨ ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„ {seconds}ì´ˆ\")\n",
    "            print(f\"ğŸ“ ê²°ê³¼ ì €ì¥: runs/detect/waste_classification\")\n",
    "            \n",
    "            # ìµœì  ëª¨ë¸ ë³µì‚¬\n",
    "            best_model_path = Path(\"runs/detect/waste_classification/weights/best.pt\")\n",
    "            if best_model_path.exists():\n",
    "                import shutil\n",
    "                shutil.copy2(best_model_path, \"best_waste_model.pt\")\n",
    "                print(\"âœ… ìµœì  ëª¨ë¸ì„ 'best_waste_model.pt'ë¡œ ë³µì‚¬í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            print(\"ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "            print(\"  - ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš” (batch_size=4 ë˜ëŠ” 2)\")\n",
    "            print(\"  - ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš” (img_size=416)\")\n",
    "            print(\"  - ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "    \n",
    "    def evaluate_model(self, model_path=\"best_waste_model.pt\"):\n",
    "        \"\"\"í›ˆë ¨ëœ ëª¨ë¸ í‰ê°€\"\"\"\n",
    "        print(f\"\\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...\")\n",
    "        \n",
    "        if not Path(model_path).exists():\n",
    "            print(f\"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # ëª¨ë¸ ë¡œë“œ\n",
    "            model = YOLO(model_path)\n",
    "            \n",
    "            # ê²€ì¦ ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€\n",
    "            results = model.val(data=self.dataset_yaml)\n",
    "            \n",
    "            print(\"âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ!\")\n",
    "            print(f\"ğŸ¯ mAP50: {results.box.map50:.3f}\")\n",
    "            print(f\"ğŸ¯ mAP50-95: {results.box.map:.3f}\")\n",
    "            \n",
    "            # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì¶œë ¥\n",
    "            if hasattr(results.box, 'ap_class_index') and results.box.ap_class_index is not None:\n",
    "                print(\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:\")\n",
    "                with open(self.dataset_yaml, 'r') as f:\n",
    "                    config = yaml.safe_load(f)\n",
    "                \n",
    "                class_names = config['names']\n",
    "                for i, class_idx in enumerate(results.box.ap_class_index):\n",
    "                    if i < len(results.box.ap50):\n",
    "                        print(f\"  {class_names[class_idx]}: {results.box.ap50[i]:.3f}\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def test_trained_model(self, model_path=\"best_waste_model.pt\"):\n",
    "        \"\"\"í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(f\"\\nğŸ¥ ì‹¤ì‹œê°„ ì“°ë ˆê¸° íƒì§€ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        if not Path(model_path).exists():\n",
    "            print(f\"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # ëª¨ë¸ ë¡œë“œ\n",
    "            model = YOLO(model_path)\n",
    "            print(\"âœ… í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "            \n",
    "            # í´ë˜ìŠ¤ ì´ë¦„ ë¡œë“œ\n",
    "            with open(self.dataset_yaml, 'r') as f:\n",
    "                config = yaml.safe_load(f)\n",
    "            class_names = config['names']\n",
    "            \n",
    "            # ì›¹ìº  ì‹œì‘\n",
    "            cap = cv.VideoCapture(0)\n",
    "            \n",
    "            if not cap.isOpened():\n",
    "                print(\"âš ï¸ ì›¹ìº ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.\")\n",
    "                self.test_sample_images(model_path)\n",
    "                return\n",
    "            \n",
    "            print(\"ğŸ¬ ì‹¤ì‹œê°„ íƒì§€ ì‹œì‘! 'q'ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.\")\n",
    "            \n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # ì¶”ë¡  ì‹¤í–‰\n",
    "                results = model(frame, conf=0.3)  # ì‹ ë¢°ë„ 30% ì´ìƒ\n",
    "                \n",
    "                # ê²°ê³¼ ê·¸ë¦¬ê¸°\n",
    "                annotated_frame = results[0].plot()\n",
    "                \n",
    "                # íƒì§€ëœ ê°ì²´ ì •ë³´ í‘œì‹œ\n",
    "                detections = results[0].boxes\n",
    "                if detections is not None and len(detections) > 0:\n",
    "                    info_text = f\"Detected: {len(detections)} objects\"\n",
    "                    cv.putText(annotated_frame, info_text, (10, 30),\n",
    "                            cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                \n",
    "                cv.imshow('Waste Detection - Press Q to quit', annotated_frame)\n",
    "                \n",
    "                if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            cap.release()\n",
    "            cv.destroyAllWindows()\n",
    "            print(\"âœ… ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    def test_sample_images(self, model_path=\"best_waste_model.pt\"):\n",
    "        \"\"\"ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(\"\\nğŸ–¼ï¸ ìƒ˜í”Œ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        # ê²€ì¦ ì´ë¯¸ì§€ë“¤ë¡œ í…ŒìŠ¤íŠ¸\n",
    "        val_images_path = Path(\"dataset/images/val\")\n",
    "        if not val_images_path.exists():\n",
    "            print(\"âŒ ê²€ì¦ ì´ë¯¸ì§€ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        sample_images = list(val_images_path.glob(\"*.jpg\"))[:5]  # ìµœëŒ€ 5ì¥\n",
    "        \n",
    "        if not sample_images:\n",
    "            print(\"âŒ í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        model = YOLO(model_path)\n",
    "        \n",
    "        for img_path in sample_images:\n",
    "            print(f\"ğŸ” í…ŒìŠ¤íŠ¸: {img_path.name}\")\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "            image = cv.imread(str(img_path))\n",
    "            \n",
    "            # ì¶”ë¡ \n",
    "            results = model(image, conf=0.3)\n",
    "            \n",
    "            # ê²°ê³¼ í‘œì‹œ\n",
    "            annotated = results[0].plot()\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            output_path = self.results_path / f\"test_{img_path.name}\"\n",
    "            cv.imwrite(str(output_path), annotated)\n",
    "            \n",
    "            print(f\"  ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}\")\n",
    "        \n",
    "        print(f\"âœ… ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼: {self.results_path}\")\n",
    "\n",
    "def quick_training_setup():\n",
    "    \"\"\"ë¹ ë¥¸ í›ˆë ¨ ì„¤ì •\"\"\"\n",
    "    print(\"âš¡ ë¹ ë¥¸ í›ˆë ¨ ì„¤ì •\")\n",
    "    print(\"=\" * 30)\n",
    "    print(\"CPUë¡œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸í•´ë³´ê¸° ìœ„í•œ ì„¤ì •ì…ë‹ˆë‹¤.\")\n",
    "    print(\"ì‹¤ì œ ì‚¬ìš©í•  ë•ŒëŠ” ë” ë§ì€ ì—í¬í¬ë¡œ í›ˆë ¨í•˜ì„¸ìš”.\")\n",
    "    \n",
    "    return {\n",
    "        'model_size': 'n',      # nano (ê°€ì¥ ê°€ë²¼ì›€)\n",
    "        'epochs': 10,           # ì ì€ ì—í¬í¬ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)\n",
    "        'batch_size': 4,        # ì‘ì€ ë°°ì¹˜ (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "        'img_size': 416         # ì‘ì€ ì´ë¯¸ì§€ í¬ê¸° (ë¹ ë¥¸ ì²˜ë¦¬)\n",
    "    }\n",
    "\n",
    "def production_training_setup():\n",
    "    \"\"\"ì‹¤ì‚¬ìš© í›ˆë ¨ ì„¤ì •\"\"\"\n",
    "    print(\"ğŸ­ ì‹¤ì‚¬ìš© í›ˆë ¨ ì„¤ì •\")\n",
    "    print(\"=\" * 30)\n",
    "    print(\"ë” ì¢‹ì€ ì„±ëŠ¥ì„ ìœ„í•œ ì„¤ì •ì…ë‹ˆë‹¤.\")\n",
    "    print(\"ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ì§€ë§Œ ë” ì •í™•í•œ ëª¨ë¸ì´ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤.\")\n",
    "    \n",
    "    return {\n",
    "        'model_size': 's',      # small (ê· í˜•ì¡íŒ ì„±ëŠ¥)\n",
    "        'epochs': 100,          # ì¶©ë¶„í•œ ì—í¬í¬\n",
    "        'batch_size': 8,        # ì ë‹¹í•œ ë°°ì¹˜ í¬ê¸°\n",
    "        'img_size': 640         # í‘œì¤€ ì´ë¯¸ì§€ í¬ê¸°\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    print(\"ğŸ‹ï¸ 3ë‹¨ê³„: YOLO ì“°ë ˆê¸° ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    trainer = WasteModelTrainer()\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ í™•ì¸\n",
    "    if not trainer.check_dataset():\n",
    "        print(\"\\nâŒ ë°ì´í„°ì…‹ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. 2ë‹¨ê³„ë¥¼ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\në‹¤ìŒ ì¤‘ ì„ íƒí•˜ì„¸ìš”:\")\n",
    "        print(\"1ï¸âƒ£ ë¹ ë¥¸ í›ˆë ¨ (í…ŒìŠ¤íŠ¸ìš© - 20 ì—í¬í¬)\")\n",
    "        print(\"2ï¸âƒ£ ì‹¤ì‚¬ìš© í›ˆë ¨ (ì •ì‹ - 100 ì—í¬í¬)\")\n",
    "        print(\"3ï¸âƒ£ ì»¤ìŠ¤í…€ ì„¤ì • í›ˆë ¨\")\n",
    "        print(\"4ï¸âƒ£ í›ˆë ¨ëœ ëª¨ë¸ í‰ê°€\")\n",
    "        print(\"5ï¸âƒ£ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"6ï¸âƒ£ ìƒ˜í”Œ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"0ï¸âƒ£ 4ë‹¨ê³„ë¡œ\")\n",
    "        \n",
    "        choice = input(\"ì„ íƒ (0-6): \").strip()\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            print(\"\\nâš¡ ë¹ ë¥¸ í›ˆë ¨ ì‹œì‘!\")\n",
    "            config = quick_training_setup()\n",
    "            trainer.train_model(**config)\n",
    "        \n",
    "        elif choice == \"2\":\n",
    "            print(\"\\nğŸ­ ì‹¤ì‚¬ìš© í›ˆë ¨ ì‹œì‘!\")\n",
    "            config = production_training_setup()\n",
    "            trainer.train_model(**config)\n",
    "        \n",
    "        elif choice == \"3\":\n",
    "            print(\"\\nğŸ› ï¸ ì»¤ìŠ¤í…€ ì„¤ì •\")\n",
    "            try:\n",
    "                epochs = int(input(\"ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ 50): \") or \"50\")\n",
    "                batch_size = int(input(\"ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ 4): \") or \"4\")\n",
    "                img_size = int(input(\"ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ 416): \") or \"416\")\n",
    "                model_size = input(\"ëª¨ë¸ í¬ê¸° (n/s/m/l/x, ê¸°ë³¸ n): \") or \"n\"\n",
    "                \n",
    "                trainer.train_model(\n",
    "                    model_size=model_size,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    img_size=img_size\n",
    "                )\n",
    "            except ValueError:\n",
    "                print(\"âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.\")\n",
    "        \n",
    "        elif choice == \"4\":\n",
    "            trainer.evaluate_model()\n",
    "        \n",
    "        elif choice == \"5\":\n",
    "            trainer.test_trained_model()\n",
    "        \n",
    "        elif choice == \"6\":\n",
    "            trainer.test_sample_images()\n",
    "        \n",
    "        elif choice == \"0\":\n",
    "            print(\"âœ… 3ë‹¨ê³„ ì™„ë£Œ! 4ë‹¨ê³„(ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ)ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b00fc8",
   "metadata": {},
   "source": [
    "### 4ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì“°ë ˆê¸° íƒì§€ ì‹œìŠ¤í…œ \n",
    "class CleanUIDetector:\n",
    "    \"\"\"ì“°ë ˆê¸° íƒì§€ ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # ëª¨ë¸ ë¡œë“œ\n",
    "        custom_model = Path(\"best_waste_model.pt\")\n",
    "        if custom_model.exists():\n",
    "            self.model = YOLO(str(custom_model))\n",
    "            self.model_type = \"Custom Waste Model\"\n",
    "            print(\"âœ… ì»¤ìŠ¤í…€ ì“°ë ˆê¸° ë¶„ë¥˜ëª¨ë¸ ë¡œë“œ\")\n",
    "        else:\n",
    "            self.model = YOLO('yolov8n.pt')\n",
    "            self.model_type = \"General Object Detection\"\n",
    "            print(\"âš ï¸ ê¸°ë³¸ í´ë˜ìŠ¤ ì‚¬ìš©\")\n",
    "        \n",
    "        # ì„¤ì •\n",
    "        self.conf_threshold = 0.25\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        # ìƒ‰ìƒ ì„¤ì • (BGR) - ë” ì˜ˆìœ ìƒ‰ìƒë“¤\n",
    "        self.box_colors = [\n",
    "            (0, 0, 255),     # Red Box\n",
    "            (0, 255, 0),     # Green Box  \n",
    "            (255, 0, 0),     # Blue Box\n",
    "            (0, 255, 255),   # Yellow Box\n",
    "            (255, 0, 255),   # Magenta Box\n",
    "            (255, 255, 0),   # Cyan Box\n",
    "        ]\n",
    "        \n",
    "        self.color_names = [\n",
    "            \"Red Box\", \"Green Box\", \"Blue Box\", \n",
    "            \"Yellow Box\", \"Magenta Box\", \"Cyan Box\"\n",
    "        ]\n",
    "    \n",
    "    def detect_objects(self, frame):\n",
    "        \"\"\"ê°ì²´ íƒì§€\"\"\"\n",
    "        results = self.model(frame, conf=self.conf_threshold, verbose=False)\n",
    "        \n",
    "        detections = []\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    cls = int(box.cls[0])\n",
    "                    \n",
    "                    class_name = self.model.names[cls] if hasattr(self.model, 'names') else f'object_{cls}'\n",
    "                    \n",
    "                    detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'confidence': conf,\n",
    "                        'class_name': class_name,\n",
    "                        'class_id': cls\n",
    "                    })\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def draw_clean_ui(self, frame, detections):\n",
    "        \"\"\"ê¹”ë”í•œ UI ê·¸ë¦¬ê¸°\"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        # ìƒë‹¨ ë°°ê²½ (ë°˜íˆ¬ëª…)\n",
    "        overlay = frame.copy()\n",
    "        cv.rectangle(overlay, (0, 0), (frame.shape[1], 120), (0, 0, 0), -1)\n",
    "        cv.addWeighted(overlay, 0.8, frame, 0.2, 0, frame)\n",
    "        \n",
    "        # íƒì§€ í˜„í™© ê³„ì‚°\n",
    "        class_counts = {}\n",
    "        for det in detections:\n",
    "            class_name = det['class_name']\n",
    "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "        \n",
    "        # ì™¼ìª½ ê¸°ë³¸ ì •ë³´\n",
    "        info_lines = [\n",
    "            f\"Objects Detected: {len(detections)}\",\n",
    "            f\"Frame: {self.frame_count}\",\n",
    "            f\"Confidence: {self.conf_threshold:.2f}\",\n",
    "            f\"Model: {self.model_type}\"\n",
    "        ]\n",
    "        \n",
    "        for i, info in enumerate(info_lines):\n",
    "            cv.putText(frame, info, (15, 25 + i * 22), \n",
    "                        cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        # ì˜¤ë¥¸ìª½ íƒì§€ í˜„í™©\n",
    "        if detections:\n",
    "            cv.putText(frame, \"Detection Summary:\", (frame.shape[1] - 280, 25),\n",
    "                        cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "            \n",
    "            y_offset = 50\n",
    "            for class_name, count in class_counts.items():\n",
    "                text = f\"{class_name}: {count}\"\n",
    "                cv.putText(frame, text, (frame.shape[1] - 280, y_offset),\n",
    "                            cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                y_offset += 22\n",
    "        \n",
    "        # íƒì§€ëœ ê°ì²´ë“¤ ê·¸ë¦¬ê¸°\n",
    "        for i, det in enumerate(detections):\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            conf = det['confidence']\n",
    "            class_name = det['class_name']\n",
    "            \n",
    "            # ìƒ‰ìƒ ì„ íƒ\n",
    "            color = self.box_colors[i % len(self.box_colors)]\n",
    "            \n",
    "            # ë°”ìš´ë”© ë°•ìŠ¤ (ë‘êº¼ìš´ í…Œë‘ë¦¬)\n",
    "            cv.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
    "            \n",
    "            # ë¼ë²¨ ë°°ê²½\n",
    "            label = f'{class_name}: {conf:.2f}'\n",
    "            (text_w, text_h), _ = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "            cv.rectangle(frame, (x1, y1 - text_h - 10), (x1 + text_w + 5, y1), color, -1)\n",
    "            \n",
    "            # ë¼ë²¨ í…ìŠ¤íŠ¸\n",
    "            cv.putText(frame, label, (x1 + 2, y1 - 5), \n",
    "                        cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # ì¤‘ì‹¬ì  (ì´ìœ ì›í˜•)\n",
    "            center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            cv.circle(frame, (center_x, center_y), 8, color, -1)\n",
    "            cv.circle(frame, (center_x, center_y), 10, (255, 255, 255), 2)\n",
    "            \n",
    "            # ê°ì²´ ë²ˆí˜¸\n",
    "            cv.putText(frame, str(i + 1), (center_x - 5, center_y + 5),\n",
    "                        cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        # í•˜ë‹¨ ìƒì„¸ íƒì§€ ì •ë³´\n",
    "        if detections:\n",
    "            # í•˜ë‹¨ ë°°ê²½\n",
    "            bottom_height = min(100, 25 * len(detections) + 40)\n",
    "            overlay2 = frame.copy()\n",
    "            cv.rectangle(overlay2, (0, frame.shape[0] - bottom_height), \n",
    "                            (frame.shape[1], frame.shape[0] - 25), (0, 0, 0), -1)\n",
    "            cv.addWeighted(overlay2, 0.8, frame, 0.2, 0, frame)\n",
    "            \n",
    "            # ìƒì„¸ ì •ë³´\n",
    "            y_pos = frame.shape[0] - bottom_height + 20\n",
    "            \n",
    "            for i, det in enumerate(detections):\n",
    "                conf = det['confidence']\n",
    "                class_name = det['class_name']\n",
    "                color_name = self.color_names[i % len(self.color_names)]\n",
    "                \n",
    "                # ìƒ‰ìƒ ì \n",
    "                color = self.box_colors[i % len(self.box_colors)]\n",
    "                cv.circle(frame, (20, y_pos + 8), 8, color, -1)\n",
    "                cv.circle(frame, (20, y_pos + 8), 10, (255, 255, 255), 1)\n",
    "                \n",
    "                # í…ìŠ¤íŠ¸\n",
    "                text = f\"[{color_name}] {class_name} {conf:.2f}\"\n",
    "                cv.putText(frame, text, (40, y_pos + 12), \n",
    "                            cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                y_pos += 25\n",
    "        \n",
    "        # ë§¨ í•˜ë‹¨ ì¡°ì‘ë²•\n",
    "        cv.putText(frame, \"SPACE: Save | +/-: Confidence | Q: Quit\", \n",
    "                    (15, frame.shape[0] - 5), cv.FONT_HERSHEY_SIMPLEX, 0.6, (150, 150, 150), 1)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def run_detection(self):\n",
    "        \"\"\"ì‹¤ì‹œê°„ íƒì§€ ì‹¤í–‰\"\"\"\n",
    "        cap = cv.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        # í•´ìƒë„ ì„¤ì •\n",
    "        cap.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        \n",
    "        print(\"\\nğŸ¬ ë‹¤ì¤‘ ê°ì²´ ì‹¤ì‹œê°„ íƒì§€ ì‹œì‘\")\n",
    "        print(\"ğŸ® ì¡°ì‘ë²•:\")\n",
    "        print(\"  SPACE: í˜„ì¬í™”ë©´ ì €ì¥\")\n",
    "        print(\"  +/- key: ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •\")\n",
    "        print(\"  Q key: ì¢…ë£Œ\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        fps_counter = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # ê°ì²´ íƒì§€\n",
    "            detections = self.detect_objects(frame)\n",
    "            \n",
    "            # UI ê·¸ë¦¬ê¸°\n",
    "            frame = self.draw_clean_ui(frame, detections)\n",
    "            \n",
    "            # FPS í‘œì‹œ\n",
    "            fps_counter += 1\n",
    "            if time.time() - start_time >= 1:\n",
    "                fps = fps_counter / (time.time() - start_time)\n",
    "                cv.putText(frame, f'FPS: {fps:.1f}', (frame.shape[1] - 100, 150), \n",
    "                            cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                fps_counter = 0\n",
    "                start_time = time.time()\n",
    "            \n",
    "            # í™”ë©´ í‘œì‹œ\n",
    "            cv.imshow('Waste Detection System', frame)\n",
    "            \n",
    "            # í‚¤ ì…ë ¥ ì²˜ë¦¬\n",
    "            key = cv.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord(' '):\n",
    "                timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f'detection_{timestamp}.jpg'\n",
    "                cv.imwrite(filename, frame)\n",
    "                print(f'ğŸ“¸ ì €ì¥: {filename}')\n",
    "            elif key == ord('+') or key == ord('='):\n",
    "                old_conf = self.conf_threshold\n",
    "                self.conf_threshold = min(0.9, self.conf_threshold + 0.05)\n",
    "                print(f'ğŸ” ì„ê³„ê°’: {old_conf:.2f} â†’ {self.conf_threshold:.2f}')\n",
    "            elif key == ord('-'):\n",
    "                old_conf = self.conf_threshold\n",
    "                self.conf_threshold = max(0.05, self.conf_threshold - 0.05)\n",
    "                print(f'ğŸ” ì„ê³„ê°’: {old_conf:.2f} â†’ {self.conf_threshold:.2f}')\n",
    "        \n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "        \n",
    "        print(f\"\\nâœ… ë‹¤ì¤‘ ê°ì²´ íƒì§€ì™„ë£Œ\")\n",
    "        print(f\"ğŸ“Š ì´ ì²˜ë¦¬ í”„ë ˆì„: {self.frame_count}\")\n",
    "\n",
    "def main():\n",
    "    print(\"ğŸ¯ ë‹¤ì¤‘ ê°ì²´ íƒì§€ ì‹œìŠ¤í…œ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    detector = CleanUIDetector()\n",
    "    detector.run_detection()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pracice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
